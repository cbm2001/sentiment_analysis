{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting fsspec (from huggingface_hub)\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Collecting requests (from huggingface_hub)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting pyyaml>=5.1 (from huggingface_hub)\n",
      "  Using cached PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)\n",
      "  Using cached typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
      "Collecting packaging>=20.9 (from huggingface_hub)\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Collecting colorama (from tqdm>=4.42.1->huggingface_hub)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface_hub)\n",
      "  Using cached charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface_hub)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface_hub)\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface_hub)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, pyyaml, packaging, idna, fsspec, filelock, colorama, charset-normalizer, certifi, tqdm, requests, huggingface_hub\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.1.0 colorama-0.4.6 filelock-3.12.0 fsspec-2023.5.0 huggingface_hub-0.15.1 idna-3.4 packaging-23.1 pyyaml-6.0 requests-2.31.0 tqdm-4.65.0 typing-extensions-4.6.3 urllib3-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 2.19.1 requires urllib3<2.0, but you have urllib3 2.0.3 which is incompatible.\n",
      "botocore 1.29.147 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.3 which is incompatible.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\certifi already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\certifi-2023.5.7.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\charset_normalizer already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\charset_normalizer-3.1.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\colorama already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\colorama-0.4.6.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\filelock already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\filelock-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\fsspec already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\fsspec-2023.5.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\huggingface_hub already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\huggingface_hub-0.15.1.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\idna already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\idna-3.4.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\packaging already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\packaging-23.1.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\PyYAML-6.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\requests already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tqdm already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tqdm-4.65.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\typing_extensions-4.6.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\typing_extensions.py already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\urllib3 already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\urllib3-2.0.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yaml already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\_yaml already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\__pycache__ already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\bin already exists. Specify --upgrade to force replacement.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git-lfs"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\git_lfs already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\git_lfs-1.6.dist-info already exists. Specify --upgrade to force replacement.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached git_lfs-1.6-py2.py3-none-any.whl (5.6 kB)\n",
      "Installing collected packages: git-lfs\n",
      "Successfully installed git-lfs-1.6\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Using cached numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Using cached pyarrow-12.0.0-cp311-cp311-win_amd64.whl (21.4 MB)\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.0.2-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Collecting requests>=2.19.0 (from datasets)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm>=4.62.1 (from datasets)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.2.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Collecting fsspec[http]>=2021.11.1 (from datasets)\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "Collecting packaging (from datasets)\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Collecting responses<0.19 (from datasets)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Using cached PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp->datasets)\n",
      "  Using cached charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0.0,>=0.11.0->datasets)\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0.0,>=0.11.0->datasets)\n",
      "  Using cached typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->datasets)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->datasets)\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.19.0->datasets)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting colorama (from tqdm>=4.62.1->datasets)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas->datasets)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, six, pyyaml, packaging, numpy, multidict, idna, fsspec, frozenlist, filelock, dill, colorama, charset-normalizer, certifi, attrs, async-timeout, yarl, tqdm, requests, python-dateutil, pyarrow, multiprocess, aiosignal, responses, pandas, huggingface-hub, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 certifi-2023.5.7 charset-normalizer-3.1.0 colorama-0.4.6 datasets-2.12.0 dill-0.3.6 filelock-3.12.0 frozenlist-1.3.3 fsspec-2023.5.0 huggingface-hub-0.15.1 idna-3.4 multidict-6.0.4 multiprocess-0.70.14 numpy-1.24.3 packaging-23.1 pandas-2.0.2 pyarrow-12.0.0 python-dateutil-2.8.2 pytz-2023.3 pyyaml-6.0 requests-2.31.0 responses-0.18.0 six-1.16.0 tqdm-4.65.0 typing-extensions-4.6.3 tzdata-2023.3 urllib3-2.0.3 xxhash-3.2.0 yarl-1.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 2.19.1 requires urllib3<2.0, but you have urllib3 2.0.3 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\n",
      "botocore 1.29.147 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.3 which is incompatible.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\aiohttp already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\aiohttp-3.8.4.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\aiosignal already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\aiosignal-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\async_timeout already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\async_timeout-4.0.2.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\attr already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\attrs already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\attrs-23.1.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\certifi already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\certifi-2023.5.7.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\charset_normalizer already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\charset_normalizer-3.1.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\colorama already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\colorama-0.4.6.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\datasets already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\datasets-2.12.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\dateutil already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\dill already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\dill-0.3.6.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\filelock already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\filelock-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\frozenlist already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\frozenlist-1.3.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\fsspec already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\fsspec-2023.5.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\huggingface_hub already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\huggingface_hub-0.15.1.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\idna already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\idna-3.4.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\multidict already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\multidict-6.0.4.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\multiprocess already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\multiprocess-0.70.14.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\numpy already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\numpy-1.24.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\packaging already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\packaging-23.1.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\pandas already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\pandas-2.0.2.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\pyarrow already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\pyarrow-12.0.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\python_dateutil-2.8.2.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\pytz already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\pytz-2023.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\PyYAML-6.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\requests already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\responses already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\responses-0.18.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\six.py already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tqdm already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tqdm-4.65.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\typing_extensions-4.6.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\typing_extensions.py already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tzdata already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tzdata-2023.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\urllib3 already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\urllib3-2.0.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\xxhash already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\xxhash-3.2.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yaml already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yarl already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yarl-1.9.2.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\_multiprocess already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\_yaml already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\__pycache__ already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\bin already exists. Specify --upgrade to force replacement.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Using cached huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.6.3-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers)\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.14.1->transformers)\n",
      "  Using cached typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
      "Collecting colorama (from tqdm>=4.27->transformers)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Installing collected packages: tokenizers, urllib3, typing-extensions, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, colorama, charset-normalizer, certifi, tqdm, requests, huggingface-hub, transformers\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.1.0 colorama-0.4.6 filelock-3.12.0 fsspec-2023.5.0 huggingface-hub-0.15.1 idna-3.4 numpy-1.24.3 packaging-23.1 pyyaml-6.0 regex-2023.6.3 requests-2.31.0 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.29.2 typing-extensions-4.6.3 urllib3-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 2.19.1 requires urllib3<2.0, but you have urllib3 2.0.3 which is incompatible.\n",
      "tensorflow-intel 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\n",
      "botocore 1.29.147 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.3 which is incompatible.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\certifi already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\certifi-2023.5.7.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\charset_normalizer already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\charset_normalizer-3.1.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\colorama already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\colorama-0.4.6.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\filelock already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\filelock-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\fsspec already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\fsspec-2023.5.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\huggingface_hub already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\huggingface_hub-0.15.1.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\idna already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\idna-3.4.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\numpy already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\numpy-1.24.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\packaging already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\packaging-23.1.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\PyYAML-6.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\regex already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\regex-2023.6.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\requests already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tokenizers already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tokenizers-0.13.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tqdm already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\tqdm-4.65.0.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\transformers already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\transformers-4.29.2.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\typing_extensions-4.6.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\typing_extensions.py already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\urllib3 already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\urllib3-2.0.3.dist-info already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\yaml already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\_yaml already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\__pycache__ already exists. Specify --upgrade to force replacement.\n",
      "WARNING: Target directory D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\\bin already exists. Specify --upgrade to force replacement.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install huggingface_hub --target D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\n",
    "!pip3 install git-lfs --target D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\n",
    "!pip3 install datasets --target D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts\n",
    "!pip3 install transformers --target D:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "datasets.config.DOWNLOADED_DATASETS_PATH = Path('E:\\\\Users\\\\Cheryl\\\\imdb_dataset\\\\')\n",
    "datasets.config.HF_DATASETS_CACHE =Path('E:\\\\Users\\\\Cheryl\\\\imdb_dataset\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (E:/Users/Cheryl/imdb_dataset/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d4a22d13be431cb1681cf34c7c5923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the imdb dataset\n",
    "imdb_dataset = datasets.load_dataset(\"imdb\", cache_dir='E:\\\\Users\\\\Cheryl\\\\imdb_dataset\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at E:\\Users\\Cheryl\\imdb_dataset\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-bc075d782b2bf9a0.arrow\n",
      "Loading cached shuffled indices for dataset at E:\\Users\\Cheryl\\imdb_dataset\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-a17dc75f4efd9725.arrow\n"
     ]
    }
   ],
   "source": [
    "# train 5000 samples so creating a smaller dataset of imdb\n",
    "train_dataset = imdb_dataset[\"train\"].shuffle(seed=50).select([j for j in list(range(3000))])\n",
    "test_dataset = imdb_dataset[\"test\"].shuffle(seed=50).select([i for i in list(range(300))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
    "# to preprocess data we are using DistilBert Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", cache_dir='E:\\\\Users\\\\Cheryl\\\\imdb_dataset\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at E:\\Users\\Cheryl\\imdb_dataset\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-96dc807c968a7d22.arrow\n",
      "Loading cached processed dataset at E:\\Users\\Cheryl\\imdb_dataset\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-6a649a090126c631.arrow\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True)\n",
    " \n",
    "tokenized_train = train_dataset.map(preprocessing_function, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocessing_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3, cache_dir='E:\\\\Users\\\\Cheryl\\\\imdb_dataset\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def compute_metrics(eval_model):\n",
    "   load_accuracy = datasets.load_metric(\"accuracy\", cache_dir='E:\\\\Users\\\\Cheryl\\\\imdb_dataset\\\\')\n",
    "   load_f1 = datasets.load_metric(\"f1\", cache_dir='E:\\\\Users\\\\Cheryl\\\\imdb_dataset\\\\')\n",
    "  \n",
    "   logits, labels = eval_model\n",
    "   predictions = numpy.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (6.23.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b89b2f8ef4a472bbcbac9a3c4f38a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip3 install ipywidgets\n",
    "import ipywidgets.widgets as widgets  # type: ignore\n",
    "from IPython.display import display  # type: ignore\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.20.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.20.2-py3-none-any.whl (227 kB)\n",
      "                                              0.0/227.5 kB ? eta -:--:--\n",
      "     --------------------------------       194.6/227.5 kB 5.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 227.5/227.5 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\cheryl\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: filelock in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (4.6.3)\n",
      "Requirement already satisfied: sympy in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\users\\cheryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.20.1\n",
      "    Uninstalling accelerate-0.20.1:\n",
      "      Successfully uninstalled accelerate-0.20.1\n",
      "Successfully installed accelerate-0.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\Cheryl\\OneDrive\\Documents\\GitHub\\sentiment_analysis\\finetuning-sentiment-analysis-model-500-samples is already a clone of https://huggingface.co/cbm2001/finetuning-sentiment-analysis-model-500-samples. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, pipeline\n",
    " \n",
    "repo_name = \"finetuning-sentiment-analysis-model-500-samples\"\n",
    " \n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    "   push_to_hub=True,\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_test,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a265d2b35349d3b63bd33bedc01a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1661\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1663\u001b[0m )\n\u001b[1;32m-> 1664\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1665\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1666\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1667\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1668\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1669\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1940\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1938\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1939\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1940\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1942\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1943\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1944\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1945\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1946\u001b[0m ):\n\u001b[0;32m   1947\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2735\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2732\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2734\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2735\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2738\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2767\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2766\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2767\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[0;32m   2768\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2769\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:763\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    760\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    761\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 763\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[0;32m    764\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    765\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    766\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    767\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    768\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    769\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    770\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    771\u001b[0m )\n\u001b[0;32m    772\u001b[0m hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    773\u001b[0m pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:583\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    579\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    581\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m    584\u001b[0m     x\u001b[39m=\u001b[39;49membeddings,\n\u001b[0;32m    585\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    586\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    587\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    588\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    589\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    590\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:359\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    357\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_state,)\n\u001b[1;32m--> 359\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    360\u001b[0m     x\u001b[39m=\u001b[39;49mhidden_state, attn_mask\u001b[39m=\u001b[39;49mattn_mask, head_mask\u001b[39m=\u001b[39;49mhead_mask[i], output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[0;32m    361\u001b[0m )\n\u001b[0;32m    362\u001b[0m hidden_state \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:295\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m sa_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    296\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    297\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    298\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    299\u001b[0m     mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    300\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    301\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    302\u001b[0m )\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[0;32m    304\u001b[0m     sa_output, sa_weights \u001b[39m=\u001b[39m sa_output  \u001b[39m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:226\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    221\u001b[0m mask \u001b[39m=\u001b[39m (mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mview(mask_reshp)\u001b[39m.\u001b[39mexpand_as(scores)  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    222\u001b[0m scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mmasked_fill(\n\u001b[0;32m    223\u001b[0m     mask, torch\u001b[39m.\u001b[39mtensor(torch\u001b[39m.\u001b[39mfinfo(scores\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mmin)\n\u001b[0;32m    224\u001b[0m )  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(scores, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    227\u001b[0m weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(weights)  \u001b[39m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m# Mask heads if we want to\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\Cheryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:1843\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1842\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
